PHOTO ORGANIZER - EXECUTION FLOW

Complete execution flow showing the 4-step pipeline with optimized clustering algorithms.

================================================================================

CONFIGURATION

All default parameters are centralized in: photo_organizer/config.py
- Clustering thresholds and weights
- Model settings (OpenAI)
- File paths and extensions
- GPS distance parameters
- Thumbnail size (512px default for cost optimization)

================================================================================

PIPELINE OVERVIEW

Entry Point: main.py → cli.main() (photo_organizer/cli.py)

1. Ingestion - Extract metadata from all images
2. Clustering - Group related photos (hierarchical strategy)
3. Classification - Identify surface types (optional)
4. Organization - Rename and organize files

================================================================================

STEP 1: INGESTION
Extract metadata from all images (EXIF, thumbnails, hashes)

Main Function: ingest(input_dir, work_dir) - photo_organizer/ingestion.py

OPERATIONS (Sequential with concurrent EXIF extraction):

1. Register HEIF Support
- register_heif() - utils/image.py
- Enables HEIC/HEIF format handling

2. Create Thumbnails (Sequential, CPU/disk intensive)
- ensure_thumb(src, dst, max_px=THUMBNAIL_SIZE) - utils/image.py
- Loops through each file with tqdm progress bar
- Creates 512px thumbnails at 50% JPEG quality (configurable via THUMBNAIL_SIZE)
- Note: 512px = single tile for GPT-4 Vision (89% cost reduction vs 768px)
- Skips files that fail thumbnail creation
- Returns: List of valid file paths

3. Extract EXIF Data (I/O-bound, concurrent with threading)
- read_exif_batch(files, max_workers=8) - utils/exif.py
- Uses ThreadPoolExecutor with 8 workers
- Calls read_exif_combined(path) for each image:
  - Runs exiftool subprocess
  - Extracts datetime (SubSecDateTimeOriginal, DateTimeOriginal, CreateDate, ModifyDate)
  - Extracts GPS (Composite:GPSLatitude/Longitude with hemisphere corrections)
- Returns: {path: {'dt': datetime, 'gps': (lat, lon)}}

4. Compute Perceptual Hashes (Sequential, on thumbnails)
- phash(thumb, hash_size=8) - utils/image.py
- Computed individually for each thumbnail during Item creation
- DCT-based perceptual hash
- Returns: ImageHash object

5. Build Item Objects
- Combines all metadata into Item data class
- Item(id, path, thumb, dt, gps, h)

Output: List of Item objects
Saved to: _work/ingest.json

================================================================================

STEP 2: CLUSTERING
Group related photos using hierarchical strategy (GPS → Datetime → Filename → Hash)

A. Extract Filename Features
- name_features(path) - utils/filename.py
- Parses patterns like IMG_1234, DSC_5678, Photo_567
- Normalizes prefixes (IMG, IMAGE, DSC → 'img')
- Returns: NameFeat(prefix, num, suffix, raw)

B. Hierarchical Clustering Strategy

PRIORITY 1: GPS-Based Clustering (Most Reliable)
- Function: cluster_gps_only(items, max_meters) - clustering/gps.py
- Groups photos within distance threshold (default: 900 feet = 274 meters)
- Uses haversine formula for accurate Earth-surface distance
- Rationale: Same location = same project site

PRIORITY 2: Fused Clustering (For non-GPS photos)
- Function: fused_cluster(items, name_map, fuse_threshold) - clustering/fused.py
- Optimization: Pre-sorted sliding window (37x faster than old O(n²) approach)
  - Sort photos ONCE by filename number
  - Check only ±64 neighbors in sorted list
  - Sequential files (IMG_55→IMG_56) are adjacent = instant match

Fused Clustering uses 3 hierarchical strategies:

1. Strategy 1: Photos WITH datetime (HIGH CONFIDENCE)
   - 0.45 * time + 0.40 * filename + 0.15 * hash
   - Time and filename are primary signals
   - Hash validates visual similarity

2. Strategy 2: NO datetime, strong filename (MEDIUM CONFIDENCE)
   - 0.75 * filename + 0.25 * hash
   - Filename is PRIMARY (sequential numbers highly predictive)
   - Requires filename score > 0.3 to use this strategy

3. Strategy 3: Weak filename (LOW CONFIDENCE)
   - Uses hash only (visual similarity)
   - Fallback when filename pattern is unclear

Filename Scoring (Optimized for sequential files):
  Same prefix + gap=1:  0.90  # IMG_55→IMG_56 (almost certain match)
  Same prefix + gap≤3:  0.80  # IMG_55→IMG_57 (very likely match)
  Same prefix + gap≤10: 0.40  # Close sequence

Output: Combined GPS + fused groups
Saved to: _work/clusters.json, _work/fused_explain_no_gps.json
Statistics: Printed at end via print_clustering_stats() - utils/stats.py

C. Test Mode: pHash-Only Clustering
- Flag: --phash-only
- Function: cluster_phash_only(items, hash_threshold) - clustering/temporal.py
- Clusters using ONLY visual similarity (ignores filename and time)
- Useful for testing: pHash alone performs poorly on construction photos
- Sequential filenames + datetime provide much better accuracy

================================================================================

STEP 3: CLASSIFICATION (Optional)
Identify surface types using OpenAI Vision API - OPTIMIZED for 90% cost reduction

Function: classify_cluster_examples(groups, batch_size, model) - ai_classification/openai_classifier.py

OPTIMIZATION: Classify only cluster examples (1 per cluster), then propagate labels
- Instead of classifying 100 images → classify 10 cluster examples
- Apply each cluster's label to all images in that cluster
- Savings: 90% fewer API calls (10 vs 100 images)
- Rationale: Images in same cluster are same project → same concrete work type

SMART EXAMPLE SELECTION: get_best_example(group) picks best representative
- Strategy 1: Prefer GPS-tagged photos (on-site, not office/reference)
- Strategy 2: Select middle image by timestamp (best lighting/setup)
  - First image = often test shot
  - Last image = often rushed
  - Middle image = photographer warmed up, good conditions
- Strategy 3: Fallback to largest file size (best quality/least compression)

Process:
1. Select best representative image from each cluster (get_best_example)
2. Classify only examples using classify_batches():
   - Encode thumbnails as base64
   - Call openai.chat.completions.create() with vision model
   - System prompt: "You are an image classifier for concrete construction photos. Return strict JSON only."
   - User prompt: Lists allowed labels and instructions
   - Structured Outputs (JSON schema):
     {
       "images": [
         {
           "id": "filename.jpg",
           "label": "stamped-concrete-patio" | "concrete-driveway" | ...,
           "confidence": 0.0-1.0,
           "descriptor": "brief description (max 6 words)"
         }
       ]
     }
3. Propagate each example's label to all images in that cluster
4. Return complete labels dict for all images

Available labels (24 concrete construction types):
- stamped concrete patio, stamped concrete driveway, stamped concrete walkway
- concrete patio, concrete driveway, concrete walkway, concrete steps
- exposed aggregate driveway, exposed aggregate patio
- retaining wall, concrete repair, concrete resurfacing
- decorative concrete, polished concrete, broom finish concrete
- acid stained concrete, epoxy floor coating, concrete foundation
- concrete slab, colored concrete, concrete overlay, pool deck
- basement floor, garage floor, unknown

Optional: Singleton Assignment
Function: assign_singletons_batched(singleton_items, multi_photo_clusters, model) - ai_classification/openai_classifier.py

Process:
- Takes singleton photos (single-image clusters)
- Compares against sample images from multi-photo clusters
- AI determines if singleton belongs to an existing cluster
- Batched processing (default: 5 singletons per API call)
- Each call includes up to 10 cluster samples (2 images per cluster)

Output: {item_id: classification_result} dictionary
Saved to: _work/labels.json

================================================================================

STEP 4: ORGANIZATION
Create organized folders and rename files with SEO-friendly names

Function: organize(groups, labels, organized_dir, brand, rotate_cities) - organization.py

Output Structure:
{output}/
├── _work/                    # Working files (metadata, thumbnails)
│   ├── ingest.json
│   ├── clusters.json
│   ├── labels.json
│   └── thumbs/
└── organized_photos/         # Final organized output (NEW)
    ├── stamped-concrete-driveway-bellevue/
    ├── concrete-patio-tacoma/
    └── manifest.json

For each cluster:

1. Determine Surface Type
- Majority vote from all labels in group
- Canonicalize using SURFACE_CANON mapping

2. Determine Location
- If GPS exists: nearest_city(gps, city_list) - utils/geo.py
  - Uses haversine() to find closest city
- If no GPS: Rotate through cities (if --rotate-cities)

3. Create Folder Name
- Format: cluster-{id}-{surface}-{city}
- Example: cluster-01-patio-bellevue

4. Process Each Photo
- Build filename: brand-surface-city-hash.jpg
- Components:
  - Brand name (if provided)
  - Surface type
  - City
  - short_hash(path) - 12-char MD5 hash for uniqueness
- Slugify all components: RC Concrete → rc-concrete
- Convert HEIC/HEIF extensions to .jpg
- Copy file: shutil.copy2(src, dst)

5. Generate Manifest
- Maps: {src, dst, cluster, label, city}

Output: Organized folder structure + manifest.json

================================================================================

KEY FUNCTIONS REFERENCE

Concurrent Operations:
  Function                    Module              Type                 Workers      Speedup
  read_exif_batch()           utils/exif.py       Threading (I/O)      8            6-8x
  Note: Thumbnails and hashes are now computed sequentially in ingestion loop

Image Processing:
- ensure_thumb(src, dst, max_px=512) - utils/image.py
- phash(image, hash_size=8) - utils/image.py
- short_hash(path, length=12) - utils/image.py
- b64(path) - ai_classification/openai_classifier.py (base64 encode for API)

EXIF Extraction:
- read_exif_combined(path) - utils/exif.py (datetime + GPS in one call)
- read_exif_batch(files, max_workers=8) - utils/exif.py (concurrent batch extraction)
- Supports: DateTimeOriginal, CreateDate, human-readable dates (e.g. "April 21, 2021")
- Prioritizes creation date over modification date

Geolocation:
- haversine(lat1, lon1, lat2, lon2) - utils/geo.py
- meters_between(gps1, gps2) - utils/geo.py
- nearest_city(gps, city_list, rotation_idx=0) - utils/geo.py

Filename Analysis:
- name_features(path) - utils/filename.py
- filename_score(feat1, feat2) - utils/filename.py

Clustering:
- cluster_gps_only(items, max_meters) - clustering/gps.py
- fused_cluster(items, name_map, fuse_threshold) - clustering/fused.py
- cluster_phash_only(items, hash_threshold) - clustering/temporal.py (test mode)
- fuse_score(item_a, item_b, name_map) - clustering/fused.py (hierarchical scoring)
- time_score(dt1, dt2) - clustering/temporal.py
- phash_score(hash1, hash2) - clustering/temporal.py

Statistics & Reporting:
- print_clustering_stats(summary, gps_count, non_gps_count) - utils/stats.py
- Displays singleton percentage, strategy breakdown, cluster counts

Classification:
- classify_cluster_examples(groups, batch_size, model) - ai_classification/openai_classifier.py (OPTIMIZED: 90% cost savings)
- get_best_example(group) - ai_classification/openai_classifier.py (smart example selection)
- classify_batches(items, batch_size, model, messages, schema) - ai_classification/openai_classifier.py (fallback/testing)
- assign_singletons_batched(singletons, clusters, model) - ai_classification/openai_classifier.py

Organization:
- organize(groups, labels, out_dir, brand, rotate_cities) - organization.py
- get_thumb_path(filename, work_dir) - cli.py (thumbnail path builder)

================================================================================

DATA FLOW

Input Images
    ↓
[Ingestion] → Item objects (id, path, thumb, dt, gps, h)
    ↓
[Clustering] → Groups: [[Item, ...], [Item, ...], ...]
    ↓
[Classification] → Labels: {item_id: {label, confidence, descriptor}}
    ↓
[Organization] → Organized folders + manifest.json

================================================================================

OUTPUT FILES

Directory Structure:
{output}/
├── _work/                              # Working files (metadata)
│   ├── ingest.json                     # All extracted metadata
│   ├── clusters.json                   # Cluster summary with strategy tags
│   ├── fused_explain_no_gps.json       # Clustering details for non-GPS photos
│   ├── labels.json                     # Classification results (if --classify enabled)
│   └── thumbs/                         # Generated thumbnails (512px JPEG)
└── organized_photos/                   # Final organized output
    ├── {label}-{city}/                 # Organized folders by label and city
    │   └── {keyword}-{city}-{brand}-{index}.jpg
    └── manifest.json                   # Complete file mapping (src → dst)

================================================================================

PERFORMANCE OPTIMIZATIONS

Clustering Speed (37x faster):
- Old: O(n²) - Re-sort for each photo (90,000 ops for 300 photos)
- New: O(n log n) - Pre-sort once, sliding window (2,400 ops for 300 photos)
- Sequential files (IMG_55→IMG_56) are adjacent in sorted list = instant match

Filename Scoring Priority:
- Sequential numbers (gap=1) score 0.90 - almost certain match
- Close sequences (gap≤3) score 0.80 - very likely match
- Based on user validation: sequential filenames are the strongest signal

Hierarchical Signal Weighting:
- GPS: Always first priority (same location = same project)
- Datetime + Filename: Best for photos with timestamps (45% time, 40% filename)
- Filename + Hash: Best for photos without datetime (75% filename, 25% hash)
- Hash only: Fallback (unreliable for construction photos with similar materials)

AI Cost Optimization:
- Thumbnail size reduced from 768px to 512px
- 512px = single tile for GPT-4 Vision (85 tokens)
- 768px = 4 tiles (765 tokens) - 9× more expensive
- Cost savings: 89% reduction ($0.19 → $0.02 per 100 images)

================================================================================
